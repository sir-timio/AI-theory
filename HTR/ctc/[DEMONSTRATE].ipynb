{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ТЕОРИЯ**\n",
    "* Привести постановку задачи распознавания рукописного текста, как задачи компьютерного зрения.\n",
    "* Привести краткий обзор методов распознавания рукописного текста аналитическими методами (без использования нейронных сетей)\n",
    "* Дать определение понятию \"Машинное обучение\" и привести некоторую сравнительную характеристику аналитического и нейросетевого подходов.\n",
    "* Рассмотреть типовые архитектуры НС, использующиеся для задач распознавания рукописного текста. Имеет смысл привести схемы архитектуры НС, дать краткое описание используемых в НС слоев, описать входные и выходные данные. Рассмотреть функции потерь, используемые для обучения этих нейронных сетей.\n",
    "* Рассмотреть (кратко) основные датасеты, использующиеся для обучения НС для распознавния рукописного текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Привести постановку задачи распознавания рукописного текста, как задачи компьютерного зрения.\n",
    "\n",
    "#### Постановка задачи\n",
    "Имеется $m$ различных классов объектов (символов), составляющих конечный алфавит $X$. Классы представлены или в форме некоторого описания, или в виде множества примеров объектов (эталонных образцов) каждого класса. \n",
    "Необходимо каждый рукописный объект в результате $классификации$ отнести к одному из $m$ классов. При этом, обычно предусмотрен $класс$ $выбросов$, который обрабатывается на более высоком уровне.  \n",
    "\n",
    "**Классификация** — процесс назначения меток объектам согласно некоторому описанию свойств объектов.<br/>\n",
    "**Классификатор** — это устройство или алгоритм, получающий в качестве входных данных описание объекта и выдающий в качестве результата метку класса.  \n",
    "**Класс выбросов** — это общий класс всех объектов, которые не удалось отнести ни к одному из известных системе классов.\n",
    "\n",
    "\n",
    "Система распознавания реализуется как классификатор. Рассмотрим несколько существующих методов реализации классификаторов:\n",
    " - шаблонные\n",
    " - структурные\n",
    " - структурно-пятенные\n",
    " - признаковые\n",
    "\n",
    "Система распознавания реализуется как классификатор. Рассмотрим несколько существующих методов реализации классификаторов:\n",
    " - шаблонные\n",
    " - структурные\n",
    " - структурно-пятенные\n",
    " - признаковые\n",
    "\n",
    "### Шаблонный классификатор\n",
    "\n",
    "Выбор производится на критерии выбора подходящего шаблона из базы. Самый простой из которых - минимум различных точек (пикселей), различных между объектом классификации и шаблоном\n",
    "\n",
    "*Достоинства*: \n",
    " - хорошее распознавание дефектных объектов (разорванных, склееных)\n",
    " - простота\n",
    " - высокая скорость\n",
    " - интерпретируемость\n",
    " \n",
    "*Недостатки*:\n",
    " - плохая точность при работе с нетипичным текстом\n",
    " - трудность обработки разномасштабного текста\n",
    "\n",
    "\n",
    "### Структурный классификатор\n",
    "\n",
    "Структурные классификаторы переводят форму символа в его топологическое представление, отражающее информацию о взаимном расположении его структурных элементов. Эти данные могут быть представлены в графовой форме.\n",
    "\n",
    "*Достоинства*:\n",
    " - инвариантность относительно типов и размеров символов\n",
    "   \n",
    "*Недостатки*:\n",
    " - медленная работа\n",
    " - трудности при обработка дефектного текста\n",
    "\n",
    "\n",
    "### Структурно-пятенный классификатор\n",
    "\n",
    "Алгоритм основан на сочетании шаблонного и структурного методов распознавания образов. При анализе объекта выделяются ключевые точки — так называемые «**пятна**». В качестве «пятен» могут выступать концы линий: узлы, изломы, крайние точки и т.п.<br>\n",
    "Подобную структуру можно сравнить со множеством шаров, нанизанных на резиновые шнуры, которые можно растягивать. После выделения «пятен» определяются связи между ними — отрезок, дуга.<br> Таким образом, итоговое описание представляет собой **граф**, который и служит объектом поиска в базе «структурно-пятенных эталонов». \n",
    "\n",
    "\n",
    "*Достоинства*:\n",
    " - инвариантность относительно типов и размеров символов\n",
    " - хорошее распознавание дефектных объектов (разорванных, склееных)\n",
    "  \n",
    "   \n",
    "*Недостатки*:\n",
    " - медленная работа\n",
    "\n",
    "\n",
    "### Признаковый классификатор\n",
    "\n",
    "Использование признакого классификатора является наиболее распространенный методом в распознавании рукописного текста. Анализ производится по вектору признаков, вычисляемых по изображению объекта. Таким образом происходит классификации набора признака, а не изображения. Для выделение признаков используется *экстрактор*, который реализуется, обычно, программно.<br>\n",
    "\n",
    "*Выделение признаков* — это процесс снижения размерности, в котором исходный набор исходных данных сокращается до более управляемых групп для дальнейшей обработки, оставаясь при этом достаточным набором для точного и полного описания исходного набора данных. Признаки играют важную роль, их главная цель – повышение скорости распознавания за счет оптимизированного представления информации об объекте классификации. Возможны различные алгоритмы выделения признаков, часто они влияют на построение и обучение предсказывающей модели. Например, можно считать число переходов от пикселей фона к пикселям символа по вертикальным и горизонтальным линиям.\n",
    "\n",
    "![](img/fs.png)\n",
    "\n",
    "Экстратор может настраиваться (обучаться) под различные данные, что дает гибкость анализа текста.<br>\n",
    "При этом, выбор важных признаков можно задавать как вручную (площадь, высота, ширина, количество отверстий и т.п.), так и предоставить эту работу классификатору (l1, l2, elasticNet регуляризации)\n",
    "\n",
    "#### Общая модель классификации\n",
    "![](img/model.jpg)\n",
    "\n",
    "*Достоинства*:\n",
    " - сильная обощающая способность\n",
    " - инвариантность и устойчивость\n",
    " - компактное хранение \n",
    " - возможная тонкая настройка\n",
    " - полезные побочные выводы о признаках\n",
    "\n",
    "*Недостатки*:\n",
    " - потеря некоторой информации об объекте\n",
    " - необходимость разработки нетривиальных метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дать определение понятию \"Машинное обучение\" и привести некоторую сравнительную характеристику аналитического и нейросетевого подходов.\n",
    "\n",
    "*Машинное обучение* — обширный подраздел искусственного интеллекта, изучающий методы построения алгоритмов, способных обучаться на данных. Различают три типа обучения: \n",
    " - обучение по прецендентам (обучение с учителем). \n",
    " - дедуктивное обучение (обучение без учителя)\n",
    " - частичное обучение (сочетание первых двух типов)\n",
    "\n",
    "\n",
    "Обучение по прецедентам основано на выявлении общих закономерностей по частным эмпирическим данным. \n",
    "Каждый прецедент представляет собой пару «объект, ответ». Требуется найти функциональную зависимость ответов от описаний объектов и построить алгоритм, принимающий на входе описание объекта и выдающий на выходе ответ. Функционал качества обычно определяется как средняя ошибка ответов, выданных алгоритмом, по всем объектам выборки.\n",
    "\n",
    "Основные типы задач обучения с учителем:\n",
    " - классификация\n",
    " - регрессия (отличается тем, что выдает число или числовой вектор принадлежности к классу)\n",
    " - ранжирование (необходима сортировка ответов модели)\n",
    " - прогнозирование (объект - временной ряд. ответ - прогноз)\n",
    " \n",
    "Основные типы задач обучения без учителя:\n",
    " - класстеризация (группировка объектов на основе метрик схожести)\n",
    " - сокращение размерности (компактное представленние данных с максимальной информативностью)\n",
    " - фильтрация выбросов (обнаружение нетипичных объектов, удаление шума)\n",
    " - заполнение пропущенных значений\n",
    "\n",
    "\n",
    "Нейронные сети, в отличие от аналитических методов, базируются на обучении по прецендетам, что позволяет создать более гибкую систему распознавания. В ходе обучения, модель может распознавать и выделить скрытие закономерности и кореляции.\n",
    "\n",
    "В чем же преимущество нейросетей перед классическими моделями машинного обучения? Стандартные модели способны хорошо описывать линейные зависимости, но ответы, которые мы хотим научится предсказываться, могут зависеть от входных данных нелинейно. Поскольку композиция линейный функций - линейная функция, на каждом слое нейросети используется нелинейная функуция активации, позволяя восстанавливать более сложные зависимости.\n",
    "\n",
    "![](img/neuron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рассмотреть типовые архитектуры НС, использующиеся для задач распознавания рукописного текста. Имеет смысл привести схемы архитектуры НС, дать краткое описание используемых в НС слоев, описать входные и выходные данные. Рассмотреть функции потерь, используемые для обучения этих нейронных сетей.\n",
    "\n",
    "### Fully-connected neural networks (FCNN) - полносвязанная нейронная сеть\n",
    "\n",
    "Каждый нейрон одного слоя связан с каждым нейроном предыдущего и следующего. Например, для изображения 10х10 имеем 10х10х3 нейронов во входном слое. Количество выходных нейронов равно размеру алфавита.<br>\n",
    "\n",
    "![](img/fully.jpg)\n",
    "\n",
    "Однако, данная архитектура является не самой удачной, поскольку имеет ряд серьезных слабостей, таких как:\n",
    " - большое число параметров\n",
    " - потеря информации о пространстве\n",
    " \n",
    "с этими проблемы борется сверточная нейронная сеть\n",
    "\n",
    "### Convolution Neural Network(CNN) - сверточная нейронная сеть\n",
    "\n",
    "Основная проблема при обработке визуальных данных заключается в том, что каждое изображение представлено в виде двумерной матрицы, где каждый элемент содержит определенный цвет, а не один одномерный вектор, который нам нужен для обучения типичных нейронных сетей.<br>\n",
    "Мы всегда могли преобразовать изображение в формат 1D, «сгладив» его. Этоозначает, что мы держим каждый пиксель рядом друг с другом , чтобы сформировать единый длинный вектор, который мы затем можем ввести в нейронную сеть. Но делая это, мы теряем много **пространственной информации**, присутствующей на изображении. Расположение каждого пикселя теперь является отдельной функцией, и, следовательно, нейронная сеть не будет фокусироваться на поиске закономерностей между соседними пикселями в изображении. <br>\n",
    "\n",
    "Типовая структура CNN (Convolution Neural Network) состоит из следующих частей:\n",
    " - сверточные слои\n",
    " - слои подвыборки\n",
    " - плотные слои\n",
    "\n",
    "### Сверточный слой \n",
    "Сверточный слой является ключевым компонентом сверточных нейронных сетей.\n",
    "\n",
    "Его целью является обнаружить значимые признаки изображения. И, если в первом слое эти признаки могут быть очень простыми (наличие вертикальных/горизонтальных линий, углов), с глубиной сети растет степень их абстракции (наличие собаки/кота/человека).\n",
    "\n",
    "Это выполняется с помощью сверточной фильтрации: производим поэлементное умножение всех значений пикселей изображения, попавших на ядро. Затем все это суммируется(еще нужно добавить параметр bias — смещение), и мы получаем какое-то число. Это число является элементом выходного слоя. Двигаем это ядро по нашему изображению с каким-то шагом(stride) и получаем очередные элементы. Из таких элементов строится новая матрица, на нее же применяется(после применения к ней функции активации) следующее ядро свертки.\n",
    "\n",
    "Те матрицы, которые мы получаем после свертки, называются картами признаков (feature maps), потому что хранят в себе некие признаки предыдущих матриц, но уже в неком другом виде.\n",
    "\n",
    "![](img/conv.jpg)\n",
    "\n",
    "\n",
    "Между составлением карт признаков происходит уменьшение признаков с помощью max pooling.\n",
    "\n",
    "Например, пулинг с функцией максимума и фильтром 2х2 с шагом 2\n",
    "![](img/pooling.png)\n",
    "\n",
    "\n",
    "После нескольких итераций остаются самые значимые признаки, которые пропускаются через полносвязную нейронную сеть\n",
    "\n",
    "###  функции потерь\n",
    "\n",
    "Функция потерь используется для расчета ошибки между  реальными и полученными ответами. Наша цель - минизировать данный функционал.\n",
    "\n",
    "В зависимости от задач, которые решает нейросеть, используются разные функции потерь. Напеример, для регрессии в основном MSE - mean squared error\n",
    "![](img/mse-loss.png)\n",
    "\n",
    "Для классификации - cross-entropy loss\n",
    "\n",
    "![](img/cross-entropy.png)\n",
    "\n",
    "Кросс-энтропия вычисляет оценку, которая суммирует среднюю разницу между фактическим и прогнозируемым распределениями вероятностей для всех классов в задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рассмотреть (кратко) основные датасеты, использующиеся для обучения НС для распознавния рукописного текста.\n",
    "\n",
    "Основные датасеты\n",
    "\n",
    "#### MNIST\n",
    "Объёмная база данных образцов рукописного написания цифр. База данных была создана после переработки оригинального набора чёрно-белых образцов размером 20x20 пикселей NIST. Создатели базы данных NIST, в свою очередь, использовали набор образцов из Бюро переписи населения США, к которому были добавлены ещё тестовые образцы, написанные студентами американских университетов. Все изображения были нормализованны, прошли сглаживание и приведены к размеру 28х28 пикселей.\n",
    "\n",
    "База данных MNIST содержит 60000 изображений пикселей для обучения и 10000 изображений для тестирования.\n",
    "Ансамбль из 5 CNN-сетей, 6-уровней выдает ошибку 0.21%\n",
    "\n",
    "![](img/mnist.png)\n",
    "\n",
    "#### firemaker\n",
    "Эта база данных содержит 1000 изображений рукописного текста, отсканированного с разрешением 300 точек на дюйм по серой шкале, содержащих страницы текста 250 авторов, по четыре страницы на автора, из четырех\n",
    "вариантов написания, один вариант на страницу. Содержимое адаптировано под \"инструкции Хаагландена\", чтобы содержать все буквы алфавита.\n",
    "Варианты таковы:\n",
    "- естественный стиль\n",
    "- прописные буквы\n",
    "- подделано (в другом стиле, неественном)\n",
    "- самостоятельно созданный\n",
    "\n",
    "\n",
    "![](img/firemaker.png)\n",
    "\n",
    "\n",
    "#### iam\n",
    "\n",
    "База данных содержит формы неограниченного рукописного текста, которые были отсканированы с разрешением 300 точек на дюйм и сохранены как изображения PNG с 256 уровнями серого.\n",
    "\n",
    "База данных почерка IAM 3.0 имеет следующую структуру:\n",
    "\n",
    "- 657 писателей предоставили образцы своего почерка\n",
    "- 1539 страниц отсканированного текста\n",
    "- 5685 отдельных предложений с пометкой\n",
    "- 13353 отдельных текстовых строки с пометкой\n",
    "- 115320 отдельных слов с пометками\n",
    "\n",
    "Все изображения форм, строк и слов предоставляются в виде файлов PNG, а соответствующие файлы меток форм, включая информацию о сегментации и различные оценочные параметры, включаются в файлы изображений в качестве метаинформации в формат XML, который описывается в файле XML и формате файла XML (DTD).\n",
    "\n",
    " На рисунке ниже - образцы полной формы, текстовой строки и некоторых извлеченных слов.\n",
    "\n",
    "![](img/iam.jpg)\n",
    "\n",
    "Ссылки:\n",
    "- https://deeplearningdemystified.com\n",
    "- http://yann.lecun.com/exdb/mnist/\n",
    "- https://zenodo.org/record/1194612#.YOW_GjYzYUE\n",
    "- https://neurohive.io/ru/osnovy-data-science\n",
    "- http://machinelearning.ru/\n",
    "- https://paperswithcode.com/\n",
    "- Impedovo, S., Downton, A. Progress in Handwriting Recognition / S. Impedovo, A. Downton. – Singapore: World Scientific Publishing, – 1997. – 622 p.\n",
    "- Shapiro, L., Stockman, G. Computer Vision / L. Shapiro, G. Stockman. – Hoboken: Prentice Hall, – 2001. – 580 p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекуретные нейронные сети (RNN)\n",
    "\n",
    "\n",
    "\n",
    "### Анализ текста полносвязной сетью\n",
    " - Все токены текста поступают на вход каждому нейрону\n",
    " - Токены анализируются изолированно друг от друга\n",
    "\n",
    "### Проблемные тексты для полносвязной сети:\n",
    " - Overall, the movie is not bad and has entertainment value.\n",
    " - Unfortunately, the movie is not so good.\n",
    " - Ice cream (мороженое, ice – лед, cream – крем, сливки)\n",
    " \n",
    " \n",
    "Необходимо анализировать текст как\n",
    "последовательность токенов, поскольку:\n",
    " - Порядок слов/символов/предложений в тексте имеет\n",
    "большой смысл\n",
    " - Нужны специальные архитектуры нейронных сетей для\n",
    "анализа последовательностей\n",
    "\n",
    "\n",
    "Идея RNN заключается в последовательном использовании информации. В традиционных нейронных сетях подразумевается, что все входы и выходы независимы. Но для многих задач это не подходит. Если вы хотите предсказать следующее слово в предложении, лучше учитывать предшествующие ему слова. RNN называются рекуррентными, потому что они выполняют одну и ту же задачу для каждого элемента последовательности, причем выход зависит от предыдущих вычислений. Еще одна интерпретация RNN: это сети, у которых есть «память», которая учитывает предшествующую информацию. Теоретически RNN могут использовать информацию в произвольно длинных последовательностях, но на практике они ограничены лишь несколькими шагами\n",
    "\n",
    "\n",
    "### Типы нейронных сетей \n",
    "\n",
    "![](img/types.jpg)\n",
    "\n",
    "## Входные данные\n",
    "\n",
    "Последовательность данных (Например, предложение или выход CNN в задаче распознавания)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Выходные данные\n",
    "\n",
    "### seq2seq\n",
    "\n",
    "Выдает последовательность на вход следующему рекурретному слою\n",
    "\n",
    "![](img/unfold.jpg)\n",
    "\n",
    "### seq2veq\n",
    "\n",
    "Выдает вектор на вход полносвязной нейронной сети\n",
    "\n",
    "![](img/seq2vec.jpg)\n",
    "\n",
    "Для обучения рекуррентных нейросетей используется разворачивание во времени и обратное распространение ошибки\n",
    "- Количество слоев в развернутой сети зависит от длины последовательности входных данных\n",
    "\n",
    "Проблема исчезающего градиента\n",
    "- При передаче от слоя к слою сигнал об изменении весов уменьшается\n",
    "- Сеть с большим количеством слоев сложно обучить\n",
    "\n",
    "Более сложные архитектуры рекуррентных нейросетей\n",
    "- LSTM (Long-Short Term Memory)\n",
    "- GRU (Gated Recurrent Unit)\n",
    "\n",
    "## SimpleHTR\n",
    "\n",
    "![](img/htr.jpg)\n",
    "\n",
    "## CNN \n",
    "\n",
    "принимает изображение 128х32  \n",
    "первый и второй слои имеют фильтр 5х5 с шагом 1  \n",
    "последние три имеют фильтр 3х3 с шагом 1  \n",
    "функция активации - ReLu  \n",
    "выдает матрицу(последовательность) 32х256  \n",
    "\n",
    "\n",
    "\n",
    "## RNN\n",
    "\n",
    "принимает последовательность из 32 векторов размера 256  \n",
    "используется LSTM  \n",
    "выход отображается на матрицы 32х80 (79 знаков и 1 пустой)  \n",
    "для каждой из 32 записей имеется 80 значений \n",
    "\n",
    "\n",
    "## CTC (Connectionist temporal classification)\n",
    "\n",
    "проблемы:\n",
    "- нужно понять, где начало и конец символа  \n",
    "- принимая наиболее вероятный символ за временной шаг, это может дать нам текст вроде «HHHHHHHHeeeellllllllloooo»\n",
    "\n",
    "Первое, что приходит в голову - удалить повторы, но тогда мы получим Helo - неправильно \n",
    "\n",
    "CTC решает обе проблемы:\n",
    "- Вы можете обучить сеть из пар (I, T), не указывая, в какой позиции персонаж находится, используя потерю CTC\n",
    "- Не нужно постобрабатывать вывод, так как декодер CTC преобразует вывод NN в окончательный текст\n",
    "\n",
    "Как это достигается?\n",
    "\n",
    "- ввести специальный символ (CTC-пробел, обозначенный в этом тексте как \"-\"), чтобы указать, что ни один символ не виден в данный момент времени\n",
    "- изменить основной текст истины T на T ', вставляя пробелы CTC и повторяя символы всеми возможными способами\n",
    "- мы знаем изображение, мы знаем текст, но мы не знаем, где расположен текст. Итак, давайте просто попробуем все возможные позиции текста \"Hi----\", \"-Hi ---\", \"--Hi--\", ...  мы также не знаем, сколько места занимает каждый символ в изображении. Так что давайте попробуем все возможные выравнивания, позволив символам повторяться, например, «HHi ----», «HHHi ---», «HHHHi--», ...\n",
    "Конечно, если мы позволим символу повторяться несколько раз, как мы будем обрабатывать настоящие дубликаты символов, такие как «l» в «Hello»? Вставляем пробел между этими символами, например, \"Hel-lo\" или \"Heeellll ------- llo\"\n",
    "рассчитать оценку для каждого возможного T '(то есть для каждого преобразования и каждой их комбинации), суммировать по всем оценкам, что приводит к потере для пары (I, T)\n",
    "\n",
    "Расшифровка: \n",
    "- выбрать символ с наибольшим количеством скором для каждого временного шага, например, «HHHHHH-eeeellll-lll - oo ---» \n",
    "- выбросить повторяющиеся символы «H-el-lo», \n",
    "- выбросить пробелы «Hello»\n",
    "\n",
    "\n",
    "![](img/ctc.jpg)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"captcha_ocr\"",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
